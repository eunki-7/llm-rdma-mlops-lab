apiVersion: apps/v1
kind: Deployment
metadata:
  name: vllm
spec:
  replicas: 4
  selector:
    matchLabels: {app: vllm}
  template:
    metadata:
      labels: {app: vllm}
    spec:
      containers:
      - name: vllm
        image: qwen-vllm:local
        args: ["bash","-lc","./start_vllm.sh"]
        ports: [{containerPort: 8000}]
        resources:
          limits:
            nvidia.com/gpu: 1
        env:
        - {name: MODEL_NAME, value: "Qwen/Qwen2-7B-Instruct"}
        - {name: TP_SIZE, value: "1"}
        - {name: HOST, value: "0.0.0.0"}
        - {name: PORT, value: "8000"}
        - {name: MAX_MODEL_LEN, value: "4096"}
        - {name: HF_HOME, value: "/models/hf_cache"}
        - {name: TRANSFORMERS_CACHE, value: "/models/hf_cache"}
        volumeMounts:
        - {name: models, mountPath: /models}
      volumes:
      - name: models
        hostPath:
          path: /models
